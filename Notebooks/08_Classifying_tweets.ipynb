{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use full for Google colab\n",
    "#!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"../data/nlp_getting_started/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/nlp_getting_started/test.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of samples in training set: 70.00%\n",
      "Percentage of samples in test set: 30.00%\n"
     ]
    }
   ],
   "source": [
    "# percentage of samples in training and test set\n",
    "print(f\"Percentage of samples in training set: {len(df_train)/(len(df_train)+len(df_test))*100:.2f}%\")\n",
    "print(f\"Percentage of samples in test set: {len(df_test)/(len(df_train)+len(df_test))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "df_train_shuffled = df_train.sample(frac=1, random_state=42)\n",
    "df_train_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4342\n",
      "1    3271\n",
      "Name: target, dtype: int64\n",
      "percentage of disaster tweets :  42.97 %\n",
      "percentage of non - disaster tweets :  57.03 %\n"
     ]
    }
   ],
   "source": [
    "# unique labels and their counts\n",
    "print(df_train_shuffled[\"target\"].value_counts())\n",
    "\n",
    "# what is the percentage of disaster tweets\n",
    "print(\"percentage of disaster tweets : \", round(len(df_train_shuffled[df_train_shuffled[\"target\"] == 1]) / len(df_train_shuffled) * 100, 2), \"%\")\n",
    "\n",
    "# what is the percentage of non-disaster tweets\n",
    "print(\"percentage of non - disaster tweets : \", round(len(df_train_shuffled[df_train_shuffled[\"target\"] == 0]) / len(df_train_shuffled) * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of samples in each split\n",
    "len(df_train_shuffled), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Hey girl you must be Toe Hobbit: Part Two: ghe Desolation of Smaug because I'm not interested in seeing you. Sorry.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Texas Seeks Comment on Rules for Changes to Windstorm Insurer http://t.co/BNNIdfZWbd\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "The things we fear most in organizations--fluctuations disturbances imbalances--are the primary sources of creativity. - Margaret Wheatley\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Am now repped by the fantastic Laura Milne @TheJonesesVoice for all your liguistic needs. And that's some tongue twister tweets\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(df_train_shuffled) - 5) # create random indexes not exceeding length of dataframe\n",
    "for row in df_train_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _,current_text, current_target = row\n",
    "    print(f\"Target: {current_target}\", \"(real disaster)\" if current_target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{current_text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(df_train_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            df_train_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # use 10% of training data for validation split\n",
    "                                                                            random_state=42)\n",
    "\n",
    "# check the number of samples in training and validation sets\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of disaster tweets in training set :  42.67 %\n",
      "percentage of non-disaster tweets in training set :  57.33 %\n",
      "percentage of disaster tweets in validation set :  45.67 %\n",
      "percentage of non-disaster tweets in validation set :  54.33 %\n"
     ]
    }
   ],
   "source": [
    "# check the percentage of disaster and non-disaster tweets in training and validation sets\n",
    "print(\"percentage of disaster tweets in training set : \", round(len(train_labels[train_labels == 1]) / len(train_labels) * 100, 2), \"%\")\n",
    "print(\"percentage of non-disaster tweets in training set : \", round(len(train_labels[train_labels == 0]) / len(train_labels) * 100, 2), \"%\")\n",
    "print(\"percentage of disaster tweets in validation set : \", round(len(val_labels[val_labels == 1]) / len(val_labels) * 100, 2), \"%\")\n",
    "print(\"percentage of non-disaster tweets in validation set : \", round(len(val_labels[val_labels == 0]) / len(val_labels) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 10 samples in training sentences and labels\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['DFR EP016 Monthly Meltdown - On Dnbheaven 2015.08.06 http://t.co/EjKRf8N8A8 #Drum and Bass #heavy #nasty http://t.co/SPHWE6wFI5',\n",
       "        'FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday',\n",
       "        'Gunmen kill four in El Salvador bus attack: Suspected Salvadoran gang members killed four people and wounded s... http://t.co/CNtwB6ScZj',\n",
       "        '@camilacabello97 Internally and externally screaming',\n",
       "        'Radiation emergency #preparedness starts with knowing to: get inside stay inside and stay tuned http://t.co/RFFPqBAz2F via @CDCgov',\n",
       "        'Investigators rule catastrophic structural failure resulted in 2014 Virg.. Related Articles: http://t.co/Cy1LFeNyV8',\n",
       "        'How the West was burned: Thousands of wildfires ablaze in #California alone http://t.co/iCSjGZ9tE1 #climate #energy http://t.co/9FxmN0l0Bd',\n",
       "        \"Map: Typhoon Soudelor's predicted path as it approaches Taiwan; expected to make landfall over southern China by S\\x89Û_ http://t.co/JDVSGVhlIs\",\n",
       "        '\\x89Ûª93 blasts accused Yeda Yakub dies in Karachi of heart attack http://t.co/mfKqyxd8XG #Mumbai',\n",
       "        'My ears are bleeding  https://t.co/k5KnNwugwT'], dtype=object),\n",
       " array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 10 samples in validation sentences and labels\n",
    "val_sentences[:10], val_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of samples in training set :  62.99 %\n",
      "percentage of samples in validation set :  7.01 %\n",
      "percentage of samples in test set :  30.0 %\n"
     ]
    }
   ],
   "source": [
    "# check the percentage of samples in training, validation and test sets of the original dataframe\n",
    "\n",
    "print(\"percentage of samples in training set : \", round(len(train_sentences) / (len(df_train_shuffled)+len(df_test)) * 100, 2), \"%\")\n",
    "print(\"percentage of samples in validation set : \", round(len(val_sentences) / (len(df_train_shuffled)+len(df_test)) * 100, 2), \"%\")\n",
    "print(\"percentage of samples in test set : \", round(len(df_test) / (len(df_train_shuffled)+len(df_test)) * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization / Embedding of text\n",
    "\n",
    "* Tokenization : Direct mapping of token to number\n",
    "\n",
    "* Embedding - create a feature vector for a token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15, 15)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average number of tokens (words) in all training sentences\n",
    "def avg_word_length(sentences):\n",
    "    \"\"\"\n",
    "    Returns the average number of words per sentence.\n",
    "    \"\"\"\n",
    "    return round(sum([len(i.split()) for i in sentences]) / len(sentences))\n",
    "\n",
    "\n",
    "\n",
    "# Get the average word length in training set\n",
    "train_avg_word_len = avg_word_length(train_sentences)\n",
    "\n",
    "# Get the average word length in validation set\n",
    "val_avg_word_len = avg_word_length(val_sentences)\n",
    "\n",
    "# Get the average word length in test set\n",
    "test_avg_word_len = avg_word_length(df_test[\"text\"])\n",
    "\n",
    "\n",
    "train_avg_word_len, val_avg_word_len, test_avg_word_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text using tensorflow layer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "#create TextVectorization object\n",
    "text_vectorizer = TextVectorization(max_tokens=10000, # how many words in the vocabulary (automatically add <OOV>)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=15, # how long should the output sequence of tokens be\n",
    "                                    pad_to_max_tokens=True) # whether to pad sequences to the longest sequence or not\n",
    "\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set text_vectorizer variables on training text\n",
    "text_vectorizer.adapt(train_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "@stormbeard @steel_lord I seen Judas Priest in 2005 when Rob came back; Scorpions as support. Fucking annihilated the place. Astonishing gig        \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[8052, 8103,    8,  834,    1, 9579,    4, 4183,   45, 2735,  440,\n",
       "          88, 4677,   26,  724]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "        \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"5 most common words: {top_5_words}\")\n",
    "print(f\"5 least common words: {bottom_5_words}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "'Trust us to get rescued by the dopey ones!' Val is hilarious shame she's probably going to die #emmerdale        \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 1.28370523e-03, -1.90831181e-02,  4.44911420e-04, ...,\n",
       "          3.32583673e-02,  8.70022923e-03,  4.41428311e-02],\n",
       "        [ 1.17532611e-02, -8.49142671e-05, -1.31330267e-02, ...,\n",
       "         -3.43974680e-03, -1.58836134e-02,  3.44605371e-03],\n",
       "        [ 4.76971157e-02, -1.42902359e-02, -3.63789573e-02, ...,\n",
       "          4.03727032e-02,  1.95386522e-02,  4.64261808e-02],\n",
       "        ...,\n",
       "        [ 1.10161789e-02, -4.61054444e-02, -3.90307792e-02, ...,\n",
       "         -1.00136995e-02,  2.85941698e-02,  1.30464546e-02],\n",
       "        [ 4.84103896e-02,  4.97270562e-02, -3.28893885e-02, ...,\n",
       "          4.05841731e-02,  3.66923548e-02,  1.70076229e-02],\n",
       "        [ 4.10092585e-02, -3.94623391e-02,  4.76190187e-02, ...,\n",
       "          2.38736533e-02, -4.16267030e-02, -3.04843914e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an Embedding using an Embedding Layer\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# create an embedding layer\n",
    "embedding = Embedding(input_dim=10000, # size of our vocabulary\n",
    "                        output_dim=128, # set the size of the embedding vector\n",
    "                        embeddings_initializer=\"uniform\", # default, initialize embedding layer\n",
    "                        input_length=15) # how long is each input sentence\n",
    "\n",
    "# get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "        \\n\\nEmbedded version:\")\n",
    "# embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-certification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
